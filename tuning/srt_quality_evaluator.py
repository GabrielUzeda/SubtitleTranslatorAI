#!/usr/bin/env python3
"""
SRT Quality Evaluator
Sistema profissional de avalia√ß√£o de qualidade de legendas SRT traduzidas
Baseado nos crit√©rios ponderados especificados pelo usu√°rio
"""

import re
import os
import json
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass
import chardet

@dataclass
class QualityScore:
    """Representa um score de qualidade com justificativa"""
    category: str
    score: float  # 0-10
    weight: float  # Peso percentual
    justification: str
    examples: List[str]
    weighted_score: float

class SRTQualityEvaluator:
    """Avaliador profissional de qualidade de legendas SRT"""
    
    def __init__(self):
        self.weights = {
            "syntax": 0.40,      # 40% - Cr√≠tico para rendering
            "fidelity": 0.15,    # 15% - Precis√£o da tradu√ß√£o
            "fluency": 0.10,     # 10% - Flu√™ncia gramatical
            "context": 0.08,     # 8% - Adequa√ß√£o contextual
            "regional": 0.07,    # 7% - Localiza√ß√£o regional
            "formality": 0.07,   # 7% - N√≠vel de formalidade
            "gender": 0.07,      # 7% - Marcadores de g√™nero
            "readability": 0.06  # 6% - Legibilidade
        }
    
    def evaluate_srt_quality(self, original_file: str, translated_file: str, target_lang: str = "pt-br") -> Dict[str, Any]:
        """
        Avalia qualidade completa de um arquivo SRT traduzido
        
        Args:
            original_file: Caminho para arquivo SRT original
            translated_file: Caminho para arquivo SRT traduzido
            target_lang: Idioma alvo ("pt-br" para portugu√™s brasileiro, "pt" ou "pt-pt" para portugu√™s de Portugal)
        
        Returns:
            Dicion√°rio com scores detalhados e an√°lise completa
        """
        
        # Carregar arquivos
        original_content = self._load_srt_file(original_file)
        translated_content = self._load_srt_file(translated_file)
        
        if not original_content or not translated_content:
            return {"error": "N√£o foi poss√≠vel carregar os arquivos SRT"}
        
        # Parsear blocos SRT
        original_blocks = self._parse_srt_blocks(original_content)
        translated_blocks = self._parse_srt_blocks(translated_content)
        
        # Executar avalia√ß√µes por categoria
        scores = {}
        
        # 1. Syntax Score (40%)
        scores["syntax"] = self._evaluate_syntax(translated_blocks, translated_content)
        
        # 2. Fidelity Score (15%)
        scores["fidelity"] = self._evaluate_fidelity(original_blocks, translated_blocks)
        
        # 3. Fluency Score (10%)
        scores["fluency"] = self._evaluate_fluency(translated_blocks)
        
        # 4. Context Score (8%)
        scores["context"] = self._evaluate_context(original_blocks, translated_blocks)
        
        # 5. Regional Score (7%)
        scores["regional"] = self._evaluate_regional(translated_blocks, target_lang)
        
        # 6. Formality Score (7%)
        scores["formality"] = self._evaluate_formality(translated_blocks)
        
        # 7. Gender Score (7%)
        scores["gender"] = self._evaluate_gender(translated_blocks)
        
        # 8. Readability Score (6%)
        scores["readability"] = self._evaluate_readability(translated_blocks)
        
        # Calcular score final (j√° est√° em escala 0-100 devido aos pesos)
        final_score = sum(scores[cat].weighted_score for cat in scores) * 10  # weighted_score j√° considera os pesos
        
        return {
            "file_info": {
                "original": original_file,
                "translated": translated_file,
                "target_language": target_lang,
                "original_blocks": len(original_blocks),
                "translated_blocks": len(translated_blocks)
            },
            "category_scores": scores,
            "final_score": final_score,
            "grade": self._get_grade(final_score),
            "summary": self._generate_summary(scores, final_score),
            "recommendations": self._generate_recommendations(scores)
        }
    
    def _load_srt_file(self, filepath: str) -> str:
        """Carrega arquivo SRT com detec√ß√£o autom√°tica de encoding"""
        try:
            # Detectar encoding
            with open(filepath, 'rb') as f:
                raw_data = f.read()
                encoding_info = chardet.detect(raw_data)
                encoding = encoding_info['encoding'] or 'utf-8'
            
            # Carregar com encoding detectado
            with open(filepath, 'r', encoding=encoding) as f:
                return f.read()
        except Exception as e:
            print(f"Erro ao carregar {filepath}: {e}")
            return ""
    
    def _parse_srt_blocks(self, content: str) -> List[Dict]:
        """Parse de blocos SRT para an√°lise estruturada"""
        blocks = []
        srt_blocks = re.split(r'\n\s*\n', content.strip())
        
        for block_text in srt_blocks:
            block_text = block_text.strip()
            if not block_text:
                continue
                
            lines = block_text.split('\n')
            if len(lines) < 2:
                continue
            
            try:
                # N√∫mero do bloco
                block_number = int(lines[0].strip())
                
                # Timestamp
                timestamp_line = lines[1].strip()
                timestamp_match = re.match(r'(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})', timestamp_line)
                
                if timestamp_match:
                    start_time = timestamp_match.group(1)
                    end_time = timestamp_match.group(2)
                    
                    # Conte√∫do (linhas restantes)
                    content_lines = lines[2:] if len(lines) > 2 else []
                    subtitle_content = '\n'.join(content_lines)
                    
                    blocks.append({
                        "number": block_number,
                        "start_time": start_time,
                        "end_time": end_time,
                        "content": subtitle_content,
                        "raw_block": block_text
                    })
            except (ValueError, IndexError):
                continue
        
        return blocks
    
    def _evaluate_syntax(self, blocks: List[Dict], full_content: str) -> QualityScore:
        """Avalia sintaxe SRT (40% do score final)"""
        issues = []
        total_blocks = len(blocks)
        error_count = 0
        
        # Verificar encoding UTF-8
        try:
            full_content.encode('utf-8')
        except UnicodeEncodeError:
            issues.append("Encoding n√£o √© UTF-8 v√°lido")
            error_count += 1
        
        # Verificar sequ√™ncia num√©rica
        expected_number = 1
        for block in blocks:
            if block["number"] != expected_number:
                issues.append(f"Numera√ß√£o incorreta: esperado {expected_number}, encontrado {block['number']}")
                error_count += 1
            expected_number += 1
        
        # Verificar formato de timestamp
        timestamp_errors = 0
        for block in blocks:
            timestamp_pattern = r'^\d{2}:\d{2}:\d{2},\d{3}$'
            if not re.match(timestamp_pattern, block["start_time"]) or not re.match(timestamp_pattern, block["end_time"]):
                timestamp_errors += 1
        
        if timestamp_errors > 0:
            issues.append(f"{timestamp_errors} timestamps com formato incorreto")
            error_count += timestamp_errors
        
        # Verificar tags HTML v√°lidas
        html_errors = 0
        for block in blocks:
            content = block["content"]
            # Verificar tags n√£o fechadas
            open_tags = re.findall(r'<(\w+)[^>]*>', content)
            close_tags = re.findall(r'</(\w+)>', content)
            
            for tag in open_tags:
                if open_tags.count(tag) != close_tags.count(tag):
                    html_errors += 1
                    break
        
        if html_errors > 0:
            issues.append(f"{html_errors} blocos com tags HTML malformadas")
            error_count += html_errors
        
        # Verificar espa√ßamento entre blocos
        spacing_errors = 0
        srt_blocks = re.split(r'\n\s*\n', full_content.strip())
        for i, block in enumerate(srt_blocks[:-1]):
            # Cada bloco deve terminar com duas quebras de linha
            if not block.endswith('\n'):
                spacing_errors += 1
        
        if spacing_errors > 0:
            issues.append(f"{spacing_errors} problemas de espa√ßamento entre blocos")
        
        # Calcular score (cr√≠tico - erros pesam muito)
        if total_blocks == 0:
            score = 0
        else:
            error_ratio = error_count / total_blocks
            score = max(0, 10 - (error_ratio * 15))  # Penalidade pesada para erros sint√°ticos
        
        justification = f"Analisados {total_blocks} blocos. " + (
            f"Encontrados {len(issues)} tipos de problemas." if issues else "Sintaxe perfeita."
        )
        
        return QualityScore(
            category="Syntax",
            score=score,
            weight=self.weights["syntax"],
            justification=justification,
            examples=issues[:3],  # Mostrar apenas primeiros 3 problemas
            weighted_score=score * self.weights["syntax"]
        )
    
    def _evaluate_fidelity(self, original_blocks: List[Dict], translated_blocks: List[Dict]) -> QualityScore:
        """Avalia fidelidade da tradu√ß√£o (15% do score)"""
        issues = []
        
        # Verificar correspond√™ncia de n√∫mero de blocos
        if len(original_blocks) != len(translated_blocks):
            issues.append(f"N√∫mero de blocos difere: {len(original_blocks)} vs {len(translated_blocks)}")
        
        # Verificar preserva√ß√£o de nomes pr√≥prios comuns
        proper_names = ["Jean Pierre Polnareff", "Silver Chariot", "Jotaro", "Dio", "Stand"]
        preservation_score = 0
        name_tests = 0
        
        for orig, trans in zip(original_blocks, translated_blocks):
            orig_content = orig["content"].lower()
            trans_content = trans["content"].lower()
            
            for name in proper_names:
                if name.lower() in orig_content:
                    name_tests += 1
                    if name.lower() in trans_content or self._is_valid_translation(name, trans_content):
                        preservation_score += 1
        
        # Verificar omiss√µes ou adi√ß√µes suspeitas
        significant_changes = 0
        for orig, trans in zip(original_blocks, translated_blocks):
            orig_words = len(orig["content"].split())
            trans_words = len(trans["content"].split())
            
            if orig_words > 0:
                ratio = trans_words / orig_words
                if ratio < 0.3 or ratio > 3.0:  # Mudan√ßa muito dr√°stica
                    significant_changes += 1
        
        if significant_changes > 0:
            issues.append(f"{significant_changes} blocos com mudan√ßas dr√°sticas de tamanho")
        
        # Calcular score
        if name_tests > 0:
            name_preservation_score = (preservation_score / name_tests) * 10
        else:
            name_preservation_score = 8  # Score padr√£o se n√£o h√° nomes para testar
        
        block_count_penalty = 0
        if len(original_blocks) != len(translated_blocks):
            block_count_penalty = 3
        
        change_penalty = (significant_changes / max(len(translated_blocks), 1)) * 5
        
        score = max(0, name_preservation_score - block_count_penalty - change_penalty)
        
        justification = f"Preserva√ß√£o de nomes: {preservation_score}/{name_tests}. " + (
            f"Problemas detectados: {len(issues)}" if issues else "Fidelidade boa."
        )
        
        return QualityScore(
            category="Fidelity",
            score=score,
            weight=self.weights["fidelity"],
            justification=justification,
            examples=issues,
            weighted_score=score * self.weights["fidelity"]
        )
    
    def _evaluate_fluency(self, blocks: List[Dict]) -> QualityScore:
        """Avalia flu√™ncia gramatical (10% do score)"""
        issues = []
        
        # Detectar problemas de flu√™ncia comuns
        fluency_problems = 0
        total_text_blocks = 0
        
        portuguese_patterns = {
            "article_agreement": r'\b(o|a|os|as)\s+\w+',
            "verb_conjugation": r'\b(√©|s√£o|est√°|est√£o|foi|foram)\b',
            "pronoun_placement": r'\b(me|te|se|nos|vos)\b'
        }
        
        for block in blocks:
            content = block["content"]
            # Remover tags HTML para an√°lise
            clean_content = re.sub(r'<[^>]+>', '', content)
            
            if len(clean_content.strip()) < 3:
                continue
                
            total_text_blocks += 1
            
            # Detectar poss√≠veis problemas
            # 1. Artigos seguidos por artigos (erro comum)
            if re.search(r'\b(o|a)\s+(o|a)\b', clean_content.lower()):
                fluency_problems += 1
                issues.append(f"Bloco {block['number']}: poss√≠vel erro de artigo duplo")
            
            # 2. Texto em ingl√™s residual
            english_words = re.findall(r'\b(the|and|you|are|this|that|with|have|will)\b', clean_content.lower())
            if len(english_words) > 2:
                fluency_problems += 1
                issues.append(f"Bloco {block['number']}: poss√≠vel texto em ingl√™s residual")
            
            # 3. Repeti√ß√µes an√¥malas
            words = clean_content.lower().split()
            if len(words) > 3:
                repeated = [word for word in set(words) if words.count(word) > 2 and len(word) > 3]
                if repeated:
                    fluency_problems += 1
                    issues.append(f"Bloco {block['number']}: repeti√ß√£o an√¥mala de palavras")
        
        # Calcular score
        if total_text_blocks == 0:
            score = 5  # Score neutro se n√£o h√° texto para analisar
        else:
            error_ratio = fluency_problems / total_text_blocks
            score = max(0, 10 - (error_ratio * 12))
        
        justification = f"Analisados {total_text_blocks} blocos de texto. Problemas de flu√™ncia: {fluency_problems}"
        
        return QualityScore(
            category="Fluency",
            score=score,
            weight=self.weights["fluency"],
            justification=justification,
            examples=issues[:3],
            weighted_score=score * self.weights["fluency"]
        )
    
    def _evaluate_context(self, original_blocks: List[Dict], translated_blocks: List[Dict]) -> QualityScore:
        """Avalia adequa√ß√£o contextual (8% do score)"""
        issues = []
        context_score = 0
        context_tests = 0
        
        # Testes contextuais espec√≠ficos para anime/a√ß√£o
        context_patterns = {
            "action_tone": ["batalha", "luta", "ataque", "poder", "for√ßa"],
            "respect_levels": ["senhor", "senhora", "voc√™", "tu"],
            "anime_terms": ["jutsu", "t√©cnica", "habilidade", "stand", "carruagem"]
        }
        
        for orig, trans in zip(original_blocks, translated_blocks):
            orig_content = orig["content"].lower()
            trans_content = trans["content"].lower()
            
            # Verificar se tom de a√ß√£o √© mantido
            if any(word in orig_content for word in ["fight", "battle", "attack", "power"]):
                context_tests += 1
                if any(word in trans_content for word in context_patterns["action_tone"]):
                    context_score += 1
                else:
                    issues.append(f"Bloco {orig['number']}: tom de a√ß√£o pode estar perdido")
            
            # Verificar tradu√ß√£o de express√µes idiom√°ticas
            if "flame" in orig_content and "table" in orig_content and "twelve" in orig_content:
                context_tests += 1
                if "meio dia" in trans_content or "meio-dia" in trans_content:
                    context_score += 2  # Bonus por tradu√ß√£o idiom√°tica correta
                elif "chama" in trans_content and "mesa" in trans_content:
                    issues.append(f"Bloco {orig['number']}: tradu√ß√£o muito literal de express√£o idiom√°tica")
        
        # Score baseado em acertos contextuais
        if context_tests > 0:
            score = min(10, (context_score / context_tests) * 10)
        else:
            score = 7  # Score padr√£o se n√£o h√° contextos espec√≠ficos para testar
        
        justification = f"Testes contextuais: {context_score}/{context_tests}. Adequa√ß√£o ao g√™nero anime/a√ß√£o."
        
        return QualityScore(
            category="Context",
            score=score,
            weight=self.weights["context"],
            justification=justification,
            examples=issues,
            weighted_score=score * self.weights["context"]
        )
    
    def _evaluate_regional(self, blocks: List[Dict], target_lang: str) -> QualityScore:
        """Avalia localiza√ß√£o regional (7% do score) - COM INTELIG√äNCIA DE IDIOMA"""
        issues = []
        brazilian_indicators = 0
        european_indicators = 0
        violations = 0
        total_checks = 0
        
        # Determinar se deve penalizar portugu√™s europeu ou brasileiro
        expect_brazilian = target_lang.lower() in ["pt-br", "portuguese-br", "brazilian"]
        expect_european = target_lang.lower() in ["pt", "pt-pt", "portuguese", "european"]
        
        # Padr√µes de portugu√™s brasileiro
        brazilian_patterns = [
            r'\bvoc√™\b', r'\bvoc√™s\b',                    # vs "tu/v√≥s"
            r'\best√°\b', r'\best√£o\b',                    # vs "est√°s/estais"  
            r'\b√¥nibus\b',                                # vs "autocarro"
            r'\bx√≠caras?\b',                              # vs "ch√°venas"
            r'\bcelular\b',                               # vs "telem√≥vel"
            r'\bgeladeira\b',                             # vs "frigor√≠fico"
            r'\bbanheiro\b',                              # vs "casa de banho"
            r'\btrem\b',                                  # vs "comboio"
            r'\bmeio cheias?\b',                          # vs "meias"
            r'\bsandu√≠che\b',                             # vs "sandes"
            r'\bsorvete\b',                               # vs "gelado"
            r'\bcal√ßada\b',                               # vs "passeio"
            r'\blegal\b',                                 # g√≠ria brasileira
            r'\bmoleque\b', r'\bmoleques\b',              # vs "mi√∫do"
            r'\bgaroto\b', r'\bgarota\b',                 # vs "rapaz/rapariga"
        ]
        
        # EXPANDIDO: Padr√µes de portugu√™s europeu (DEZENAS de palavras)
        european_patterns = [
            # Pronomes e conjuga√ß√µes
            r'\btuas?\b', r'\bvossas?\b',                 # vs "suas"
            r'\best√°s\b', r'\bestou\b', r'\bestais\b',    # vs "est√°/est√£o"
            r'\btendes\b', r'\bsois\b',                   # arca√≠smo europeu
            
            # Vocabul√°rio cotidiano
            r'\bautocarro\b',                             # vs "√¥nibus"
            r'\btelem√≥vel\b',                             # vs "celular"
            r'\bfrigor√≠fico\b',                           # vs "geladeira"
            r'\bcasa de banho\b',                         # vs "banheiro"
            r'\bch√°venas?\b',                             # vs "x√≠caras"
            r'\bmeias-ch√°venas\b',                        # vs "meio cheias"
            r'\bcomboio\b',                               # vs "trem"
            r'\bsandes\b',                                # vs "sandu√≠che"
            r'\bgelado\b',                                # vs "sorvete"
            r'\bpasseio\b',                               # vs "cal√ßada"
            r'\brapariga\b',                              # vs "garota/menina"
            r'\bmi√∫dos?\b',                               # vs "garotos/crian√ßas"
            r'\bputos?\b',                                # g√≠ria PT-PT
            r'\bmarretas?\b',                             # g√≠ria PT-PT
            r'\bmacaquinho\b',                            # vs "macac√£o"
            r'\bdescal√ßos?\b',                            # vs "descal√ßos" (forma BR √© igual mas contexto diferente)
            
            # Comida e bebida
            r'\bbicas?\b',                                # vs "cafezinho"
            r'\bgal√£o\b',                                 # caf√© com leite PT-PT
            r'\bfinos?\b',                                # cerveja pequena
            r'\bimperiais?\b',                            # cerveja (algumas regi√µes)
            r'\bpast√©is de nata\b',                       # vs "past√©is de Bel√©m"
            r'\bbroas?\b',                                # tipo de p√£o doce
            r'\bfarinheiras?\b',                          # tipo de enchido
            r'\bmorcelas?\b',                             # vs "morcilha"
            
            # Vestu√°rio
            r'\bcamisolas?\b',                            # vs "su√©ter/blusa"
            r'\bfatos?\b',                                # vs "ternos"
            r'\bcal√ß√µes\b',                               # vs "shorts"
            r'\btosses?\b',                               # vs "gorros"
            r'\bt√©nis\b',                                 # vs "t√™nis"
            
            # Casa e objetos
            r'\bestore\b',                                # vs "persiana"
            r'\bliga√ß√£o\b',                               # vs "chamada telef√¥nica"
            r'\bcanalizador\b',                           # vs "encanador"
            r'\belectricista\b',                          # vs "eletricista"
            r'\bcomputador port√°til\b',                   # vs "notebook/laptop"
            r'\brato\b',                                  # vs "mouse"
            r'\bteclado\b',                               # igual mas contexto
            r'\becr√£\b',                                  # vs "tela"
            r'\bvisor\b',                                 # vs "tela/monitor"
            
            # Verbos e express√µes espec√≠ficas
            r'\balugar\b',                                # vs "alugar" (forma BR)
            r'\bdeitar fora\b',                           # vs "jogar fora"
            r'\bapanhar\b',                               # vs "pegar"
            r'\bata logo\b',                              # express√£o PT-PT
            r'\bestou farto\b',                           # vs "estou cheio"
            r'\bque caca\b',                              # express√£o PT-PT
            r'\bque chatice\b',                           # vs "que chato"
            r'\bestou tramado\b',                         # g√≠ria PT-PT
            r'\best√°s √† vontade\b',                       # vs "fique √† vontade"
            
            # Express√µes temporais e quantidades
            r'\bpara o ano\b',                            # vs "ano que vem"
            r'\bganda\b',                                 # g√≠ria: "muito grande"
            r'\bfixe\b',                                  # vs "legal/maneiro"
            r'\bporreiro\b',                              # vs "legal/bacana"
            r'\bbu√©\b',                                   # vs "muito"
            
            # Dinheiro e compras
            r'\bc√™ntimos\b',                              # vs "centavos"
            r'\bhipermercado\b',                          # vs "hipermercado" (igual mas contexto)
            r'\btabacaria\b',                             # vs "tabacaria"
            r'\bestanco\b',                               # banca de jornais
            
            # Tr√¢nsito e transporte
            r'\bmatr√≠cula\b',                             # vs "placa"
            r'\bparque de estacionamento\b',              # vs "estacionamento"
            r'\bsinal\b',                                 # vs "sem√°foro"
            r'\bpassadeira\b',                            # vs "faixa de pedestres"
            r'\brotunda\b',                               # vs "rotat√≥ria"
            r'\bautoestrada\b',                           # vs "rodovia/autoestrada"
            
            # Educa√ß√£o
            r'\bfaculdade\b',                             # contexto diferente
            r'\bliceu\b',                                 # vs "col√©gio"
            r'\bprim√°ria\b',                              # vs "fundamental"
            
            # NOVO: Detectar gagueira n√£o traduzida (problema espec√≠fico)
            r'\bH-Hold\b', r'\bW-What\b', r'\bN-No\b', r'\bS-Stop\b', r'\bB-But\b'
        ]
        
        for block in blocks:
            content = block["content"].lower()
            clean_content = re.sub(r'<[^>]+>', '', content)
            
            if len(clean_content.strip()) < 3:
                continue
            
            # Contar indicadores brasileiros
            for pattern in brazilian_patterns:
                if re.search(pattern, clean_content):
                    brazilian_indicators += 1
                    total_checks += 1
            
            # Contar indicadores europeus
            for pattern in european_patterns:
                if re.search(pattern, clean_content):
                    european_indicators += 1
                    total_checks += 1
        
        # L√ìGICA INTELIGENTE: s√≥ penalizar se n√£o bater com o idioma alvo
        if expect_brazilian:
            # Se esperamos portugu√™s brasileiro, penalizar portugu√™s europeu
            violations = european_indicators
            for block in blocks:
                content = block["content"].lower()
                clean_content = re.sub(r'<[^>]+>', '', content)
                for pattern in european_patterns:
                    if re.search(pattern, clean_content):
                        if "ch√°venas" in pattern:
                            issues.append(f"Bloco {block['number']}: ERRO CR√çTICO - 'ch√°venas' (portugu√™s de Portugal, esperado: pt-br)")
                        elif any(stutter in pattern for stutter in ["H-Hold", "W-What", "N-No", "S-Stop", "B-But"]):
                            issues.append(f"Bloco {block['number']}: ERRO - gagueira n√£o traduzida: {pattern}")
                        else:
                            issues.append(f"Bloco {block['number']}: portugu√™s europeu detectado (esperado: pt-br): {pattern}")
                        break  # Um erro por bloco
        
        elif expect_european:
            # Se esperamos portugu√™s europeu, penalizar portugu√™s brasileiro
            violations = brazilian_indicators
            for block in blocks:
                content = block["content"].lower()
                clean_content = re.sub(r'<[^>]+>', '', content)
                for pattern in brazilian_patterns:
                    if re.search(pattern, clean_content):
                        issues.append(f"Bloco {block['number']}: portugu√™s brasileiro detectado (esperado: pt-pt): {pattern}")
                        break  # Um erro por bloco
        
        else:
            # Idioma n√£o especificado ou gen√©rico - n√£o penalizar nenhum
            violations = 0
            issues.append("Idioma alvo n√£o espec√≠fico - avalia√ß√£o regional neutra")
        
        # Calcular score baseado nas viola√ß√µes
        if total_checks == 0:
            score = 8  # Score padr√£o se n√£o h√° indicadores regionais
        else:
            violation_ratio = violations / total_checks
            score = max(0, 10 - (violation_ratio * 12))  # Penalidade moderada mas firme
        
        # Bonus por usar o dialeto correto
        if expect_brazilian and brazilian_indicators > european_indicators:
            score = min(10, score + 1)
        elif expect_european and european_indicators > brazilian_indicators:
            score = min(10, score + 1)
        
        # Penalidade extra para viola√ß√µes cr√≠ticas
        critical_violations = len([issue for issue in issues if "CR√çTICO" in issue])
        if critical_violations > 0:
            score = max(0, score - (critical_violations * 2))
        
        # Determinar justificativa baseada no idioma alvo
        if expect_brazilian:
            justification = f"Alvo: pt-br | Brasileiro: {brazilian_indicators}, Europeu (viola√ß√µes): {european_indicators}"
        elif expect_european:
            justification = f"Alvo: pt-pt | Europeu: {european_indicators}, Brasileiro (viola√ß√µes): {brazilian_indicators}"
        else:
            justification = f"Alvo: gen√©rico | Brasileiro: {brazilian_indicators}, Europeu: {european_indicators}"
        
        return QualityScore(
            category="Regional",
            score=score,
            weight=self.weights["regional"],
            justification=justification,
            examples=issues[:5],  # Mostrar at√© 5 exemplos
            weighted_score=score * self.weights["regional"]
        )
    
    def _evaluate_formality(self, blocks: List[Dict]) -> QualityScore:
        """Avalia n√≠vel de formalidade (7% do score)"""
        issues = []
        
        # Detectar inconsist√™ncias de formalidade
        formal_indicators = 0
        informal_indicators = 0
        
        formal_patterns = [r'\bsenhor\b', r'\bsenhora\b', r'\bvossa\b']
        informal_patterns = [r'\bvoc√™\b', r'\bcara\b', r'\bmano\b']
        
        for block in blocks:
            content = block["content"].lower()
            clean_content = re.sub(r'<[^>]+>', '', content)
            
            for pattern in formal_patterns:
                formal_indicators += len(re.findall(pattern, clean_content))
            
            for pattern in informal_patterns:
                informal_indicators += len(re.findall(pattern, clean_content))
        
        total_indicators = formal_indicators + informal_indicators
        
        if total_indicators == 0:
            score = 8  # Score neutro se n√£o h√° indicadores
        elif formal_indicators == 0 or informal_indicators == 0:
            score = 10  # Consistente em uma dire√ß√£o
        else:
            # Penalizar mistura excessiva
            consistency = abs(formal_indicators - informal_indicators) / total_indicators
            score = 5 + (consistency * 5)
        
        # Para anime, informalidade √© geralmente apropriada
        if informal_indicators > formal_indicators:
            score = min(10, score + 1)
        
        justification = f"Formal: {formal_indicators}, Informal: {informal_indicators}. Consist√™ncia avaliada."
        
        return QualityScore(
            category="Formality",
            score=score,
            weight=self.weights["formality"],
            justification=justification,
            examples=issues,
            weighted_score=score * self.weights["formality"]
        )
    
    def _evaluate_gender(self, blocks: List[Dict]) -> QualityScore:
        """Avalia marcadores de g√™nero (7% do score)"""
        issues = []
        
        # Verificar concord√¢ncia de g√™nero b√°sica
        gender_errors = 0
        total_gender_checks = 0
        
        # Padr√µes problem√°ticos comuns
        problematic_patterns = [
            r'\bo\s+\w+a\b',  # "o mesa" (artigo masculino + substantivo feminino)
            r'\ba\s+\w+o\b',  # "a carro" (artigo feminino + substantivo masculino)
        ]
        
        for block in blocks:
            content = block["content"].lower()
            clean_content = re.sub(r'<[^>]+>', '', content)
            
            for pattern in problematic_patterns:
                matches = re.findall(pattern, clean_content)
                if matches:
                    gender_errors += len(matches)
                    total_gender_checks += len(matches)
                    issues.append(f"Bloco {block['number']}: poss√≠vel erro de concord√¢ncia de g√™nero")
        
        # Para este contexto, se n√£o h√° erros evidentes, assume-se que est√° correto
        if total_gender_checks == 0:
            score = 9  # Score alto por padr√£o se n√£o h√° problemas detectados
        else:
            error_ratio = gender_errors / total_gender_checks
            score = max(0, 10 - (error_ratio * 15))
        
        justification = f"Verifica√ß√µes de g√™nero: {gender_errors} erros em {total_gender_checks} casos analisados"
        
        return QualityScore(
            category="Gender",
            score=score,
            weight=self.weights["gender"],
            justification=justification,
            examples=issues[:2],
            weighted_score=score * self.weights["gender"]
        )
    
    def _evaluate_readability(self, blocks: List[Dict]) -> QualityScore:
        """Avalia legibilidade (6% do score)"""
        issues = []
        
        line_length_violations = 0
        line_count_violations = 0
        total_blocks = 0
        
        for block in blocks:
            content = block["content"]
            clean_content = re.sub(r'<[^>]+>', '', content)  # Remove HTML
            
            if len(clean_content.strip()) < 2:
                continue
                
            total_blocks += 1
            lines = clean_content.split('\n')
            
            # Verificar n√∫mero de linhas por bloco (‚â§3)
            if len(lines) > 3:
                line_count_violations += 1
                issues.append(f"Bloco {block['number']}: {len(lines)} linhas (m√°ximo recomendado: 3)")
            
            # Verificar caracteres por linha (‚â§40)
            for i, line in enumerate(lines):
                if len(line.strip()) > 40:
                    line_length_violations += 1
                    if len(issues) < 5:  # Limitar exemplos
                        issues.append(f"Bloco {block['number']}, linha {i+1}: {len(line)} caracteres (m√°ximo: 40)")
        
        # Calcular score
        if total_blocks == 0:
            score = 5
        else:
            length_penalty = (line_length_violations / total_blocks) * 5
            count_penalty = (line_count_violations / total_blocks) * 3
            score = max(0, 10 - length_penalty - count_penalty)
        
        justification = f"Blocos analisados: {total_blocks}. Viola√ß√µes de comprimento: {line_length_violations}, linhas: {line_count_violations}"
        
        return QualityScore(
            category="Readability",
            score=score,
            weight=self.weights["readability"],
            justification=justification,
            examples=issues[:3],
            weighted_score=score * self.weights["readability"]
        )
    
    def _is_valid_translation(self, original_name: str, translated_content: str) -> bool:
        """Verifica se nome foi traduzido adequadamente"""
        translations = {
            "silver chariot": ["carruagem de prata", "silver chariot"],
            "jean pierre polnareff": ["jean pierre polnareff", "polnareff"],
            "stand": ["stand", "alma"]
        }
        
        original_lower = original_name.lower()
        if original_lower in translations:
            return any(trans in translated_content.lower() for trans in translations[original_lower])
        
        return False
    
    def _get_grade(self, score: float) -> str:
        """Converte score num√©rico em nota qualitativa"""
        if score >= 90:
            return "A+ (Excelente)"
        elif score >= 80:
            return "A (Muito Bom)"
        elif score >= 70:
            return "B (Bom)"
        elif score >= 60:
            return "C (Regular)"
        elif score >= 50:
            return "D (Ruim)"
        else:
            return "F (Falha)"
    
    def _generate_summary(self, scores: Dict[str, QualityScore], final_score: float) -> str:
        """Gera resumo executivo da avalia√ß√£o"""
        strongest = max(scores.values(), key=lambda x: x.score)
        weakest = min(scores.values(), key=lambda x: x.score)
        
        return f"""
        Score Final: {final_score:.1f}/100 ({self._get_grade(final_score)})
        
        Ponto Forte: {strongest.category} ({strongest.score:.1f}/10)
        Ponto Fraco: {weakest.category} ({weakest.score:.1f}/10)
        
        A tradu√ß√£o {'atende aos padr√µes profissionais' if final_score >= 70 else 'precisa de melhorias'}.
        """
    
    def _generate_recommendations(self, scores: Dict[str, QualityScore]) -> List[str]:
        """Gera recomenda√ß√µes baseadas nos scores"""
        recommendations = []
        
        for category, score_obj in scores.items():
            if score_obj.score < 7:
                if category == "syntax":
                    recommendations.append("üîß Corrigir problemas de sintaxe SRT - PRIORIDADE ALTA")
                elif category == "fidelity":
                    recommendations.append("üìù Revisar fidelidade da tradu√ß√£o")
                elif category == "fluency":
                    recommendations.append("‚úèÔ∏è Melhorar flu√™ncia e gram√°tica")
                elif category == "context":
                    recommendations.append("üé≠ Ajustar adequa√ß√£o contextual")
                elif category == "readability":
                    recommendations.append("üëÅÔ∏è Otimizar legibilidade das legendas")
        
        if not recommendations:
            recommendations.append("‚úÖ Tradu√ß√£o de alta qualidade - manter padr√£o atual")
        
        return recommendations

def main():
    """Fun√ß√£o principal para teste do avaliador"""
    evaluator = SRTQualityEvaluator()
    
    # Exemplo de uso
    original_file = "../example/example.eng.srt"
    translated_file = "../example/example.pt-br.srt"
    
    if os.path.exists(original_file) and os.path.exists(translated_file):
        # NOVO: passando target_lang baseado no nome do arquivo traduzido
        target_lang = "pt-br"  # Default para portugu√™s brasileiro
        if "pt-pt" in translated_file.lower() or ".pt." in translated_file.lower():
            target_lang = "pt-pt"
        
        result = evaluator.evaluate_srt_quality(original_file, translated_file, target_lang)
        
        print("üèÜ AVALIA√á√ÉO DE QUALIDADE SRT")
        print("=" * 60)
        print(f"Arquivo Original: {result['file_info']['original']}")
        print(f"Arquivo Traduzido: {result['file_info']['translated']}")
        print(f"Idioma Alvo: {result['file_info']['target_language']}")
        print(f"Score Final: {result['final_score']:.1f}/100 ({result['grade']})")
        print()
        
        print("üìä SCORES POR CATEGORIA:")
        for category, score_obj in result['category_scores'].items():
            print(f"{score_obj.category}: {score_obj.score:.1f}/10 (peso: {score_obj.weight*100:.0f}%)")
            print(f"   {score_obj.justification}")
            if score_obj.examples:
                print(f"   Exemplos: {'; '.join(score_obj.examples[:2])}")
            print()
        
        print("üí° RECOMENDA√á√ïES:")
        for rec in result['recommendations']:
            print(f"   {rec}")
        
        # Salvar relat√≥rio
        timestamp = int(time.time())
        report_file = f"quality_report_{timestamp}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nüíæ Relat√≥rio salvo em: {report_file}")
    
    else:
        print("‚ùå Arquivos de exemplo n√£o encontrados")

if __name__ == "__main__":
    import time
    main() 